{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b3e8c8e",
   "metadata": {},
   "source": [
    "# Attention\n",
    "\n",
    "There are problems where fully connected neural nets and CNNs are not suitable. One of the examples is dealing with sequences of different lengths.\n",
    "\n",
    "In this notebook, we will see how Self-Attention can solve the sorting problem. Given an rbitrary length sequence of digits, the task is to return sorted one.\n",
    "\n",
    "```\n",
    "Input:  [1 1 1 8 4 6 8 5 8 2 6]\n",
    "Output: [1 1 1 2 4 5 6 6 8 8 8]\n",
    "```\n",
    "\n",
    "Let's implement the problem using a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf1f3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Attention, Input, Dense, LayerNormalization, Flatten, MultiHeadAttention\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba3422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = np.eye(10)\n",
    "\n",
    "def pad(list_of_seq):\n",
    "    N = max([len(seq) for seq in list_of_seq])\n",
    "    return np.stack([np.pad(seq, (0, N - len(seq)))\n",
    "                     for seq in list_of_seq])\n",
    "\n",
    "def generator(max_seq_len, batch_size=32):\n",
    "    while True:\n",
    "        X = [np.random.randint(10, size=np.random.randint(max_seq_len))\n",
    "             for _ in range(batch_size)]\n",
    "        y = [np.sort(x) for x in X]\n",
    "        yield one_hot[pad(X)], one_hot[pad(y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b82c635",
   "metadata": {},
   "source": [
    "Now we can take a look at a small batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad7b9fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input:  [7 9 4 0 0 0 0 0 0 0 0]\n",
      "Output: [4 7 9 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Input:  [4 2 0 0 0 0 0 0 0 0 0]\n",
      "Output: [0 2 4 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Input:  [0 8 7 3 8 0 4 5 8 3 3]\n",
      "Output: [0 0 3 3 3 4 5 7 8 8 8]\n",
      "\n",
      "Input:  [5 7 0 5 1 0 5 0 0 0 0]\n",
      "Output: [0 0 1 5 5 5 7 0 0 0 0]\n",
      "\n",
      "Input:  [4 6 3 6 0 0 0 0 0 0 0]\n",
      "Output: [3 4 6 6 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "gen = generator(12, batch_size=5)\n",
    "X, y = next(gen)\n",
    "for inp, out in zip(X, y):\n",
    "    print('\\nInput: ', inp.argmax(axis=1))\n",
    "    print('Output:', out.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f37ebc",
   "metadata": {},
   "source": [
    "Note, that due to the padding this problem becomes even harder since 0 has different interpretations depending on where it is located. It is a good idea to pad with -1's instead, but let's stick with the current implementation to make it more challenging for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53018f9-1b10-4f14-9be1-5e0b2bc1f8d5",
   "metadata": {},
   "source": [
    "## Self-Attention\n",
    "\n",
    "In principle idea of self-attention is quite simple. Input vector gets multiplied by three matrixes - $Q, K, V$ to form **Q**uery, **K**ey and **V**alue vectors. Then **Q**uery and **K**ey are combined between the sequences to get weights which are then used to weight **V**alues before summing them up.\n",
    "\n",
    "![Attention](img/self_attention.gif)\n",
    "\n",
    "There are a lot of good explanations online if you want to go deeper and understand the math behind it - https://peterbloem.nl/blog/transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a212a-08aa-4853-a46f-04515398e9ab",
   "metadata": {},
   "source": [
    "## Transformer Block\n",
    "\n",
    "To use self-attention effectively we need to harness a couple of tricks. The first is to mix it up with fully connected layers and introduce some skip connections.\n",
    "\n",
    "![Transformer Block](img/transformer_block.png)\n",
    "\n",
    "Since it is possible to repeat Transformer Blocks let's a for loop (for now it will be executed only once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345ecdd2-c5eb-4cd0-bbc5-aa3f66e26dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hidden=32, num_heads=16, num_blocks=1):\n",
    "\n",
    "    inp = Input((None, 10))\n",
    "    emb = Dense(hidden)(inp)\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        enc = MultiHeadAttention(num_heads=num_heads, key_dim=hidden)(emb, emb)\n",
    "        enc = LayerNormalization(epsilon=1e-5)(enc + emb)\n",
    "\n",
    "        fcn = Dense(hidden * 4, activation='relu')(enc)\n",
    "        fcn = Dense(hidden)(fcn)\n",
    "        emb = LayerNormalization(epsilon=1e-5)(fcn + enc)\n",
    "\n",
    "    out = Dense(10, activation='softmax')(emb)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b4154",
   "metadata": {},
   "source": [
    "Let's define a helper function that plots sequences and an image and prints out a small sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbdbd35f-d256-43df-9637-d53dfaed5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, gen, seq_to_print=5):\n",
    "    X, y = next(gen)\n",
    "    pred = model(X).numpy().argmax(axis=-1)\n",
    "    real = y.argmax(axis=-1)\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(pred)\n",
    "    plt.axis('off')\n",
    "    plt.title('Prediction')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(real)\n",
    "    plt.axis('off')\n",
    "    plt.title('Actual seq')\n",
    "    plt.show()\n",
    "    for p, a in zip(pred[:seq_to_print],\n",
    "                    real[:seq_to_print]):\n",
    "        print('\\nPrediction:', p)\n",
    "        print('Actual seq:', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f59b59c",
   "metadata": {},
   "source": [
    "Finally we are ready to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b997cc1-8477-4aa9-900c-abdc363d7111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 21:47:15.419906: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-22 21:47:15.420010: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-08-22 21:47:15.990242: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-08-22 21:47:15.991041: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 21:47:16.233765: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 8s 36ms/step - loss: 1.1721\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 1.0920\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 1.0749\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 1.0552\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 1.0364\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 1.0297\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 1.0499\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 1.0398\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 1.0212\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 1.0447\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 0 0 0]\n",
      "Actual seq: [1 2 2 3 4 4 4 5 6 6 7 7 7 7 8 9 0 0 0]\n",
      "\n",
      "Prediction: [1 1 5 1 1 1 1 1 1 5 5 1 0 0 0 0 0 0 0]\n",
      "Actual seq: [1 1 3 4 5 5 6 7 7 8 9 9 0 0 0 0 0 0 0]\n",
      "\n",
      "Prediction: [7 7 7 7 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual seq: [2 7 7 8 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Prediction: [3 3 2 3 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual seq: [0 2 3 5 7 9 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Prediction: [9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 0 0 0 0]\n",
      "Actual seq: [1 4 4 5 5 6 7 7 8 9 9 9 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "gen = generator(max_seq_len=20)\n",
    "\n",
    "model = build_model()\n",
    "model.fit(gen, steps_per_epoch=200, epochs=10)\n",
    "\n",
    "eval_model(model, gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6f729-5c19-4637-9580-5010bcf35dad",
   "metadata": {},
   "source": [
    "At this point, the model can learn to deal with sequence length and can pick the element that is most common but fails with sorting problem... Clearly, we lack something that allows the model to learn sequential nature.\n",
    "\n",
    "## Positional Embeddings\n",
    "\n",
    "To resolve the problem we will add random weights for each position! We fix those *positional embeddings* before generating sequences and then add them to the inputs. The code below should be self-explanatory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c8217d-1963-4985-a86a-11907c016eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_generator(max_seq_len):\n",
    "    positional_embedding = np.random.random((max_seq_len, 10))\n",
    "    gen = generator(max_seq_len)\n",
    "    while True:\n",
    "        X, y = next(gen)\n",
    "        N = y.shape[1]\n",
    "        X += positional_embedding[:N]\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf9aec5",
   "metadata": {},
   "source": [
    "Let's retrain the model using updated generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f18d00b-29d2-414c-8300-04253b92ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/200 [..............................] - ETA: 1:21 - loss: 2.2106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 21:48:32.104336: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 8s 37ms/step - loss: 1.1802\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.8474\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.7291\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.6720\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.6303\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.5987\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.5833\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.5571\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.5374\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.5235\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction: [0 1 1 1 1 2 2 3 2 6 6 6 6 7 7 7 8 8 7]\n",
      "Actual seq: [0 0 1 1 1 2 2 2 3 3 4 6 6 6 7 7 7 8 8]\n",
      "\n",
      "Prediction: [1 4 4 4 4 4 4 5 5 5 5 7 7 7 9 9 9 0 9]\n",
      "Actual seq: [0 1 3 3 4 4 4 4 5 5 5 6 7 7 7 8 9 9 9]\n",
      "\n",
      "Prediction: [1 1 1 3 3 7 7 0 0 8 0 0 0 0 0 0 0 0 0]\n",
      "Actual seq: [0 0 0 1 1 2 3 5 6 7 8 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Prediction: [0 1 3 3 3 7 5 7 7 7 8 8 8 8 8 8 9 0 0]\n",
      "Actual seq: [1 2 3 5 5 6 7 7 7 7 7 8 8 8 8 8 8 0 0]\n",
      "\n",
      "Prediction: [0 1 2 4 4 4 4 4 7 8 8 8 8 8 0 0 0 0 0]\n",
      "Actual seq: [0 1 2 4 4 4 5 6 7 7 8 8 8 9 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "gen = positional_generator(max_seq_len=20)\n",
    "\n",
    "model = build_model()\n",
    "model.fit(gen, steps_per_epoch=200, epochs=10)\n",
    "\n",
    "eval_model(model, gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1d1717",
   "metadata": {},
   "source": [
    "Much better! You can try to remove the attention layer to convince yourself that this net will fail without it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4800e5-1acc-4e34-a11a-e181b5d5a3b9",
   "metadata": {},
   "source": [
    "## Final Architecture\n",
    "\n",
    "For sure we can add more layers to get more power. It's already implemented above, we just need to pass `num_blocks=3` when constructing the model.\n",
    "\n",
    "![Transformer Block](img/transformer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecb53ce9-ec6c-4daf-8d82-291cc5517a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 21:49:46.419997: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 20s 94ms/step - loss: 1.0445\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.5815\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.4544\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 0.3942\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3435\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.3268\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 19s 94ms/step - loss: 0.2976\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2707\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.2787\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 19s 97ms/step - loss: 0.2496\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction: [0 1 3 7 7 8 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual seq: [0 1 3 7 7 8 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Prediction: [2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual seq: [2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Prediction: [0 0 1 2 2 2 3 3 5 4 5 5 5 7 7 9 9 9 0]\n",
      "Actual seq: [0 0 1 2 2 3 3 3 4 4 5 5 5 5 7 9 9 9 0]\n",
      "\n",
      "Prediction: [0 3 3 5 7 7 8 8 9 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual seq: [0 3 4 5 7 7 8 8 9 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Prediction: [0 0 0 0 0 2 7 8 8 9 0 0 0 0 0 0 0 0 0]\n",
      "Actual seq: [0 0 0 0 1 2 7 8 8 9 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "gen = positional_generator(max_seq_len=20)\n",
    "\n",
    "model = build_model(num_blocks=3)\n",
    "model.fit(gen, steps_per_epoch=200, epochs=10)\n",
    "\n",
    "eval_model(model, gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1422bf",
   "metadata": {},
   "source": [
    "Training is still quite fast and this time results are nearly perfect. From time to time model messes up with zeros, but that is expected as discussed in the problem formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3204a349-8d1e-43a5-a7f4-0f3dbf9334a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Age of Transformers\n",
    "\n",
    "Attention is widely used for language and is finding its way into language, voice, vision, and basically any field that uses sequences or can be expressed as a sequence. It was popularized with a paper named [Attention Is All You Need](https://arxiv.org/abs/1706.03762). Usually similarly to autoencoders, there is a block that encodes input data followed by a decoder. It can be from the same domain, for example as in translation problems, but even more interestingly it can be different domains, for example, encoding text and then decoding it as an image!\n",
    "\n",
    "Widely known [GPT-3](https://openai.com/api/) used Transformers with attention to creating stunning text completions that can seam intelligent. It is common to see attention used in summarization, [translation](https://www.deepl.com/translator), and text classification solutions. [DALL-E 2](https://openai.com/dall-e-2/) as well as [midjourney](https://www.midjourney.com/showcase/) used them to create stunning art from the text descriptions.\n",
    "\n",
    "\n",
    "## (re)Sources:\n",
    "\n",
    "- Good explanation - https://peterbloem.nl/blog/transformers.\n",
    "- More simple examples - https://github.com/greentfrapp/attention-primer.\n",
    "- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
